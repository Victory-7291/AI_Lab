# 标识与感知 --实验2

    
## 1.实现LED1闪烁

### 创建项目
```
  1.在电脑磁盘中创建`LED`文件夹  
  2.在IAR Embedding Worchbench中点击`Project`->`Create New Project`，选择以创建的`LED`文件夹  
  3.在IAR Embedding Worchbench中点击`File`->`New`->`File`，创建`main.c` `LED.c` `LED.h`  
  4.在IAR Embedding Worchbench中右击`LED - Debug`->`Add`， 把创建的三个文件加到项目的workspace中  
  5.在IAR Embedding Worchbench中右击`LED - Debug`->`Options`->`Debug`， Driver选择Texas instruments, 选中Overide default, 点击ok  
```
### 编写代码

复制以下代码到文件中  

main.c:
```
#include "LED.h"

void main(void)
{
  Led_Init();
  while(1)
  {
    LED1_Off();
    Delay(10);
    LED1_On();
    Delay(10);
  }
}

```

LED.c:
```
#include <ioCC2530.h>
#include "LED.h"

void Led_Init(void)
{
  P1SEL &= ~(1<<0);
  P1DIR |=  (1<<0);
  LED1 = 0;
}

void Delay(unsigned int time)
{
  unsigned int i,j;
  for(i = 0; i<time; i++)
    for(j = 0; j < 10000; j++);
}

```

LED.h:
```
#include <ioCC2530.h>         

#define LED1 P1_0             
#define LED1_On() LED1=1;
#define LED1_Off() LED1=0;

extern void Led_Init(void);
extern void Delay(unsigned int time);

```
### 编译并烧录



  
-------------------------------------------------------------------------------------------------------------------

  
### 了解InternVL2的设计模式，可以大概描述InternVL2的模型架构和训练流程：

        1.InternViT:
            模型架构：使用InternLM2-20B、InternViT-6B和MLP。
            训练方法：通过监督预训练、对比预训练和与LLM联合训练来提升模型性能。
        2.Pixel Shuffle:
            技术原理：用于减少高分辨率图像处理中的计算资源消耗，通过调整采样因子来降低token数量。
        3.Dynamic High-Resolution:
            预定义的长宽比：根据计算资源，设置最多12个tile，有35种长宽比的排列组合。
            匹配和分割：选择最接近的长宽比，调整大小后切割成448x448的tiles。
        4.多任务输出:
            任务特化embedding：使用VisionLLMv2技术初始化任务特化embedding，用于图像生成、分割、检测等。
            工作流程：视觉提示和文本提示通过图像编码器和文本分词器处理，然后通过大型语言模型生成各种任务的输出。
        5.训练:
            第一阶段：训练MLP，使用高质量预训练数据。
            第二阶段：ViT+MLP+LLM联合训练，使用高质量
  
-------------------------------------------------------------------------------------------------------------------


### 了解LMDeploy部署多模态大模型的核心代码，并运行提供的gradio代码，在UI界面体验与InternVL2的对话：


按照教程配置环境，运行demo,与InternVL2交互：

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-12%2019-27-54.png "2024-11-20%2021-42-15.png")

  
-------------------------------------------------------------------------------------------------------------------


微调前，错把肠粉认成叉烧：


![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-14%2010-07-15.png "2024-11-20%2021-42-31.png")

  
-------------------------------------------------------------------------------------------------------------------


### 了解XTuner，并利用给定数据集微调InternVL2-2B后，再次启动UI界面，体验模型美食鉴赏能力的变化:


在xtuner/xtuner/config中添加InternVL2-2B微调的配置文件：

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-12%2020-05-49.png "2024-11-20%2021-43-08.png")

  
-------------------------------------------------------------------------------------------------------------------


启动微调：

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-12%2020-37-18.png "2024-11-20%2021-42-31.png")

  
-------------------------------------------------------------------------------------------------------------------


内存溢出，超出30%A100显存两倍左右：

![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-12%2021-03-19.png "2024-11-20%2021-42-15.png")

  
-------------------------------------------------------------------------------------------------------------------


修改config文件中的bitch_size从4改为2，微调完成：

![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-13%2021-23-49.png "2024-11-20%2021-43-08.png")

  
-------------------------------------------------------------------------------------------------------------------


借助已有的权重文件转换脚本，把.pth格式的权重文件转换为.safetensors：

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-13%2021-44-22.png "2024-11-20%2021-43-50.png")

  
-------------------------------------------------------------------------------------------------------------------


修改demo.py中模型的路径，然后运行：

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-13%2021-49-43.png "2024-11-20%2021-43-50.png")

  
-------------------------------------------------------------------------------------------------------------------


微调后的模型成功识别了肠粉：

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/2024-12-14%2010-15-06.png "2024-11-20%2021-42-31.png")

  
-------------------------------------------------------------------------------------------------------------------


# 进阶任务：

## 将训练好的模型上传到huggingface

  
在终端登录huggingface

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/Screenshot%20from%202025-01-14%2017-21-51.png "2024-11-20%2021-43-50.png")

  
-------------------------------------------------------------------------------------------------------------------


创建模型仓库后git clone到开发机，在本地仓库加入权重转换过的模型文件，然后通过镜像站push到huggingface

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/Screenshot%20from%202025-01-14%2020-20-19.png "2024-11-20%2021-43-50.png")

  
-------------------------------------------------------------------------------------------------------------------


huggingface格式的模型文件成功上传到huggingface

  
![erro](https://github.com/Victory-7291/AI_Lab/raw/main/images/Screenshot%20from%202025-01-14%2020-20-36.png "2024-11-20%2021-42-31.png")

  
-------------------------------------------------------------------------------------------------------------------
